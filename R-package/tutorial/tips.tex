
\section{How to plot a vector?}

If \ttt{v} a matrix or data frame with \ttt{x} and \ttt{y} columns, you can draw a plot as:

\begin{verbatim}
> plotLineChart(list(v))
\end{verbatim}

\section{How to plot several vectors?}

If \ttt{v1}, \\ttt{v2}, \ttt{v3} are matrices or data frames with \ttt{x} and \ttt{y} columns,
the plot containing the 3 lines can be generated by:

\begin{verbatim}
> plotLineChart(list(a=v1, b=v2, c=v3))
\end{verbatim}

The lines are named \ttt{'a'}, \ttt{'b'} and \ttt{'c'}, these names can be used to specify
properties of the lines:

\begin{verbatim}
> plotLineChart(list(a=v1, b=v2, c=v3), 'Line.Color/a'='red', 'Symbols.Type/b'='Square', 'Line.Type/c'='SampleHold')
\end{verbatim}

These line names are displayed on the legend too:

\begin{verbatim}
> plotLineChart(list(a=v1, b=v2, c=v3), Legend.Display='true')
\end{verbatim}

If you want to generate a plot from vectors in a dataset, use the \ttt{makeLineChartDataset()} to select
the vectors and give the lines sensible names:

\begin{verbatim}
> vs <- makeLineChartDataset(dataset, '\${configname}/\${runnumber} - \${module} \${name}')
> plotLineChart(vs, Legend.Display='true')
\end{verbatim}

\section{How to compute and plot a histogram of a vector?}

If \ttt{v} is a numeric vector, then the \ttt{hist()} function from the \ttt{graphics} package
can be used to generate a histogram object and draw a histograme plot.

\begin{verbatim}
> h <- hist(v)
\end{verbatim}

If you want to put several histogram on a single plot:

\begin{verbatim}
> h1 <- hist(v1, plot=FALSE)
> h2 <- hist(v2, plot=FALSE)
> plot(h1)
> plot(h2, add=TRUE)
\end{verbatim}

If \ttt{d} is a loaded dataset containing histogram data, then \ttt{makeHistograms()} can generate
histogram objects:

\begin{verbatim}
> hs <- makeHistograms(d, '{module} {name}') 
\end{verbatim}

The result is a list of histgram objects, the elements are identified by module and statistic name.

\section{How to plot a histogram together with its cumulative distribution function?}

\section{How to transform a dataset into another dataset where all scalars are averaged across replications?}

\begin{verbatim}
d <- averageScalarsAcrossReplications(dataset)
\end{verbatim}

To compute confidence intervals as well:

\begin{verbatim}
d <- averageScalarsAcrossReplications(dataset, conf.level=0.95)
\end{verbatim}

\section{How to create a bar chart of some scalars where error bars indicate confidence interval?}

\begin{verbatim}
heigths <- makeBarChartDataset(dataset, rows=c('measurement'), columns=c('name'))
conf.intervals <- makeBarChartDataset(dataset, rows=c('measurement'), columns=c('name'), conf.int(0.95) )
plotBarChart(heigths, conf.int=conf.intervals, Legend.Display='true', Legend.Anchoring='NorthWest')
\end{verbatim}

\section{How to average some scalars across modules?}

For example, if you want the average of \ttt{'avgQueueLength'} across all queue modules:

\begin{verbatim}
ql <- subset(d$scalars, grepl('.*\\.queue', module) & name='avgQueueLength')
mean(ql$value)
\end{verbatim}

\section{How to sum scalars grouped by modules?}

Assume you want to compute the sum of drop counts for each node in the
omnetpp/samples/routing/Net60 network.

First load the scalars generated by the simulation:

\begin{verbatim}
> d <- loadDataset('/home/tomi/work/omnetpp/samples/routing/results/Net60-0.sca')
\end{verbatim}

Each node may have several input gates and a message queue for each input port.
You can select the drop counts of the queues by:

\begin{verbatim}
> dc <- subset(d$scalars, name=='drop:count' & grepl('.*queue.*',module))
> dc

     resultkey                          runid                                                        file                 module       name value
10           9 Net60-0-20100816-10:48:41-7648 /home/tomi/work/omnetpp/samples/routing/results/Net60-0.sca  Net60.rte[0].queue[0] drop:count     0
21          20 Net60-0-20100816-10:48:41-7648 /home/tomi/work/omnetpp/samples/routing/results/Net60-0.sca  Net60.rte[1].queue[0] drop:count     0
30          29 Net60-0-20100816-10:48:41-7648 /home/tomi/work/omnetpp/samples/routing/results/Net60-0.sca  Net60.rte[1].queue[1] drop:count     0
39          38 Net60-0-20100816-10:48:41-7648 /home/tomi/work/omnetpp/samples/routing/results/Net60-0.sca  Net60.rte[1].queue[2] drop:count     0
50          49 Net60-0-20100816-10:48:41-7648 /home/tomi/work/omnetpp/samples/routing/results/Net60-0.sca  Net60.rte[2].queue[0] drop:count     0
61          60 Net60-0-20100816-10:48:41-7648 /home/tomi/work/omnetpp/samples/routing/results/Net60-0.sca  Net60.rte[3].queue[0] drop:count     0
72          71 Net60-0-20100816-10:48:41-7648 /home/tomi/work/omnetpp/samples/routing/results/Net60-0.sca  Net60.rte[4].queue[0] drop:count    12
81          80 Net60-0-20100816-10:48:41-7648 /home/tomi/work/omnetpp/samples/routing/results/Net60-0.sca  Net60.rte[4].queue[1] drop:count     0
90          89 Net60-0-20100816-10:48:41-7648 /home/tomi/work/omnetpp/samples/routing/results/Net60-0.sca  Net60.rte[4].queue[2] drop:count     0
99          98 Net60-0-20100816-10:48:41-7648 /home/tomi/work/omnetpp/samples/routing/results/Net60-0.sca  Net60.rte[4].queue[3] drop:count     0
...
\end{verbatim}

To sum the drop counts for each node:

\begin{verbatim}
> r <- aggregate(list(value=dc$value),
                 list(runid=dc$runid,file=dc$file,module=sub('\\.queue\\[[0-9]+\\]', '', dc$module),name=dc$name),
                 sum)
\end{verbatim}

If you want to add these scalars to the original dataset, first generate \ttt{resultkey} for the new scalars,
and use \ttt{rbind}:

\begin{verbatim}
r <- cbind(list(resultkey=seq(from=max(d$scalars$resultkey, d$vectors$resultkey, d$histograms$resultkey) + 1,
                              length.out=nrow(r))),
           r)
d$scalars <- rbind(d$scalars, r)
\end{verbatim}

\section{How to compute the mean, stddev, min, max etc of vectors?}

If the vector is loaded into a dataset, then the \ttt{mean}, \ttt{sd}, \ttt{min}, \ttt{max}
functions can be used:

\begin{verbatim}
> d <- loadDataset('Aloha.vec', add('vector'))
> d <- loadVectors(d, NULL)
> vs <- split(d$vectordata$y, d$vectordata$resultkey)
> lapply(vs, mean)
> lapply(vs, sd)
> lapply(vs, min)
> lapply(vs, max)
> lapply(vs, summary)
\end{verbatim}

Or if you have the \ttt{doBy} package installed:

\begin{verbatim}
> require(doBy)
> d <- loadDataset('Aloha.vec', add('vector'))
> d <- loadVectors(d, NULL)
> summaryBy(y ~ resultkey, d$vectordata, FUN = list(mean, sd, min, max))
\end{verbatim}

The current version does not support computing the summary statistics without loading the vectors,
but it is planned in a future version to do so.

\section{How to plot a scatter chart where the X axis is some run iteration
variable (i.e. \$numHosts)?}

Iteration variables are saved as scalars as well, so you can write:

\begin{verbatim}
> d <- makeScatterChartDataset(dataset, xModule='.', xName='numHosts')
> plotLineChart(d)
\end{verbatim}

\section{How to plot a 3D chart where the X,Y axes are run iteration variables?}

In this example we create a 3D plot of the \ttt{total receive time} as a function
of the mean \ttt{iaTime} and \ttt{numOfHosts} from the Aloha simulation.

First create a data frame containing the values of the scalars for each run:
 
\begin{verbatim}
> require(reshape)
> d <- loadDataset('/home/tomi/work/omnetpp-resultfiles/R-package/inst/extdata/PureAlohaExperiment-*.sca')
> x <- subset(d$scalars, name=='mean', c('runid','value'))
> y <- subset(d$scalars, name=='numHosts', c('runid', 'value'))
> z <- subset(d$scalars, name=='total receive time', c('runid','value'))
> data3d <- rename(merge(merge(x, y, by='runid'), z, by='runid'),
                   c(value.x='mean', value.y='numHosts', value='total receive time'))
\end{verbatim}

Now you can use the \ttt{lattice} package to draw a 3D scatter plot (\ttt{cloud()}) or a
3D surface plot (\ttt{wireframe()}):

\begin{verbatim}
> require(lattice)
> cloud(`total receive time` ~ numHosts * mean, data=data3d)
\end{verbatim}

